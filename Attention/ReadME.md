**In this Section, I have discussed the following topics**

  * Seq2seq model
  * Attention better than Seq2seq
  * How Attention works
  * Scoring function of attention 
  * Transformer model
  * Basic implementation of Attention network.
