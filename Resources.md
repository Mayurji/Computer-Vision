### Deep Learning Resources

* [Chris Olah's Blog on LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
* [Edwin Chen's Blog on LSTM](http://blog.echen.me/2017/05/30/exploring-lstms/)
* [Andrej Karpathy's Lecture](https://www.youtube.com/watch?v=iX5V1WpxxkY)
* [GRU](http://www.cs.toronto.edu/~guerzhoy/321/lec/W09/rnn_gated.pdf)
* [Demo](https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html)
* [Matrix Multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication)
* [Activation Functions](https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions)
* [MSE](https://en.wikipedia.org/wiki/Mean_squared_error)
* [Cross Entropy](https://www.ics.uci.edu/~pjsadows/notes.pdf)
* [Linear Combination](http://linear.ups.edu/html/section-LC.html)
* [Partial Derivatives](http://www.columbia.edu/itc/sipa/math/calc_rules_multivar.html)
* [Common Derivatives](http://tutorial.math.lamar.edu/pdf/Common_Derivatives_Integrals.pdf)
* [Learning Rate 1](http://blog.datumbox.com/tuning-the-learning-rate-in-gradient-descent/)
* [Learning Rate 2](http://cs231n.github.io/neural-networks-3/#loss)
* [Gradient Clipping](https://arxiv.org/abs/1211.5063)

